{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob #Directorios\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob \n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = sorted(glob('*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((pd.read_json(file) for file in jsons),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>places</th>\n",
       "      <th>id</th>\n",
       "      <th>organisations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAHIA COCOA REVIEW</td>\n",
       "      <td>Showers continued throughout the week in\\nthe ...</td>\n",
       "      <td>1987-02-26 15:01:01.790000</td>\n",
       "      <td>[cocoa]</td>\n",
       "      <td>[el-salvador, usa, uruguay]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STANDARD OIL &lt;SRD&gt; TO FORM FINANCIAL UNIT</td>\n",
       "      <td>Standard Oil Co and BP North America\\nInc said...</td>\n",
       "      <td>1987-02-26 15:02:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEXAS COMMERCE BANCSHARES &lt;TCB&gt; FILES PLAN</td>\n",
       "      <td>Texas Commerce Bancshares Inc's Texas\\nCommerc...</td>\n",
       "      <td>1987-02-26 15:03:27.510000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TALKING POINT/BANKAMERICA &lt;BAC&gt; EQUITY OFFER</td>\n",
       "      <td>BankAmerica Corp is not under\\npressure to act...</td>\n",
       "      <td>1987-02-26 15:07:13.720000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[usa, brazil]</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE</td>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>1987-02-26 15:10:44.600000</td>\n",
       "      <td>[grain, wheat, corn, barley, oat, sorghum]</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "0                                BAHIA COCOA REVIEW   \n",
       "1         STANDARD OIL <SRD> TO FORM FINANCIAL UNIT   \n",
       "2        TEXAS COMMERCE BANCSHARES <TCB> FILES PLAN   \n",
       "3      TALKING POINT/BANKAMERICA <BAC> EQUITY OFFER   \n",
       "4  NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE   \n",
       "\n",
       "                                                body  \\\n",
       "0  Showers continued throughout the week in\\nthe ...   \n",
       "1  Standard Oil Co and BP North America\\nInc said...   \n",
       "2  Texas Commerce Bancshares Inc's Texas\\nCommerc...   \n",
       "3  BankAmerica Corp is not under\\npressure to act...   \n",
       "4  The U.S. Agriculture Department\\nreported the ...   \n",
       "\n",
       "                         date                                      topics  \\\n",
       "0  1987-02-26 15:01:01.790000                                     [cocoa]   \n",
       "1         1987-02-26 15:02:20                                         NaN   \n",
       "2  1987-02-26 15:03:27.510000                                         NaN   \n",
       "3  1987-02-26 15:07:13.720000                                         NaN   \n",
       "4  1987-02-26 15:10:44.600000  [grain, wheat, corn, barley, oat, sorghum]   \n",
       "\n",
       "                        places  id organisations  \n",
       "0  [el-salvador, usa, uruguay]   1           NaN  \n",
       "1                        [usa]   2           NaN  \n",
       "2                        [usa]   3           NaN  \n",
       "3                [usa, brazil]   4           NaN  \n",
       "4                        [usa]   5           NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21578, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              737\n",
       "body              2535\n",
       "date                 0\n",
       "topics           10211\n",
       "places            2780\n",
       "id                   0\n",
       "organisations    20697\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21578 entries, 0 to 21577\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   title          20841 non-null  object\n",
      " 1   body           19043 non-null  object\n",
      " 2   date           21578 non-null  object\n",
      " 3   topics         11367 non-null  object\n",
      " 4   places         18798 non-null  object\n",
      " 5   id             21578 non-null  int64 \n",
      " 6   organisations  881 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].replace(np.nan,'unknown')\n",
    "df['topics'] = df['topics'].replace(np.nan,'unknown')\n",
    "df['places'] = df['places'].replace(np.nan,'unknown')\n",
    "df['organisations'] = df['organisations'].replace(np.nan,'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "body             0\n",
       "date             0\n",
       "topics           0\n",
       "places           0\n",
       "id               0\n",
       "organisations    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>places</th>\n",
       "      <th>id</th>\n",
       "      <th>organisations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAHIA COCOA REVIEW</td>\n",
       "      <td>Showers continued throughout the week in\\nthe ...</td>\n",
       "      <td>1987-02-26 15:01:01.790000</td>\n",
       "      <td>[cocoa]</td>\n",
       "      <td>[el-salvador, usa, uruguay]</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STANDARD OIL &lt;SRD&gt; TO FORM FINANCIAL UNIT</td>\n",
       "      <td>Standard Oil Co and BP North America\\nInc said...</td>\n",
       "      <td>1987-02-26 15:02:20</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEXAS COMMERCE BANCSHARES &lt;TCB&gt; FILES PLAN</td>\n",
       "      <td>Texas Commerce Bancshares Inc's Texas\\nCommerc...</td>\n",
       "      <td>1987-02-26 15:03:27.510000</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>3</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TALKING POINT/BANKAMERICA &lt;BAC&gt; EQUITY OFFER</td>\n",
       "      <td>BankAmerica Corp is not under\\npressure to act...</td>\n",
       "      <td>1987-02-26 15:07:13.720000</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[usa, brazil]</td>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE</td>\n",
       "      <td>The U.S. Agriculture Department\\nreported the ...</td>\n",
       "      <td>1987-02-26 15:10:44.600000</td>\n",
       "      <td>[grain, wheat, corn, barley, oat, sorghum]</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>5</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "0                                BAHIA COCOA REVIEW   \n",
       "1         STANDARD OIL <SRD> TO FORM FINANCIAL UNIT   \n",
       "2        TEXAS COMMERCE BANCSHARES <TCB> FILES PLAN   \n",
       "3      TALKING POINT/BANKAMERICA <BAC> EQUITY OFFER   \n",
       "4  NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE   \n",
       "\n",
       "                                                body  \\\n",
       "0  Showers continued throughout the week in\\nthe ...   \n",
       "1  Standard Oil Co and BP North America\\nInc said...   \n",
       "2  Texas Commerce Bancshares Inc's Texas\\nCommerc...   \n",
       "3  BankAmerica Corp is not under\\npressure to act...   \n",
       "4  The U.S. Agriculture Department\\nreported the ...   \n",
       "\n",
       "                         date                                      topics  \\\n",
       "0  1987-02-26 15:01:01.790000                                     [cocoa]   \n",
       "1         1987-02-26 15:02:20                                     unknown   \n",
       "2  1987-02-26 15:03:27.510000                                     unknown   \n",
       "3  1987-02-26 15:07:13.720000                                     unknown   \n",
       "4  1987-02-26 15:10:44.600000  [grain, wheat, corn, barley, oat, sorghum]   \n",
       "\n",
       "                        places  id organisations  \n",
       "0  [el-salvador, usa, uruguay]   1       unknown  \n",
       "1                        [usa]   2       unknown  \n",
       "2                        [usa]   3       unknown  \n",
       "3                [usa, brazil]   4       unknown  \n",
       "4                        [usa]   5       unknown  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body'] = df['body'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>places</th>\n",
       "      <th>id</th>\n",
       "      <th>organisations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13457</th>\n",
       "      <td>SOVIET GRAIN PRODUCTS MINISTRY CRITICISED</td>\n",
       "      <td>The Soviet Communist Party has criticised\\nthe...</td>\n",
       "      <td>1987-04-07 06:13:53.760000</td>\n",
       "      <td>[grain]</td>\n",
       "      <td>[ussr]</td>\n",
       "      <td>13458</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>CHRYSLER &lt;C&gt; TO CLOSE INDIANA ELECTRICAL PLANT</td>\n",
       "      <td>Chrysler Corp said over the next two\\nyears it...</td>\n",
       "      <td>1987-03-09 15:14:31.080000</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>3319</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17501</th>\n",
       "      <td>SPECTRA-PHYSICS &lt;SPY&gt; BOARD REJECTS TENDER OFFER</td>\n",
       "      <td>Spectra-Physics Inc said its\\nboard rejected a...</td>\n",
       "      <td>1-JUN-1987 09:09:43.36</td>\n",
       "      <td>[acq]</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>17502</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10213</th>\n",
       "      <td>CANAMAX, PACIFIC TRANS-OCEAN APPROVE PRODUCTION</td>\n",
       "      <td>&lt;Canamax Resources Inc&gt; and &lt;Pacific\\nTrans-Oc...</td>\n",
       "      <td>26-MAR-1987 17:26:07.23</td>\n",
       "      <td>[gold]</td>\n",
       "      <td>[canada]</td>\n",
       "      <td>10214</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10363</th>\n",
       "      <td>JAPAN SETS ASIDE YEN FUNDS TO PREVENT DLR FALL</td>\n",
       "      <td>The 50-day provisional 1987/88 budget,\\nadopte...</td>\n",
       "      <td>27-MAR-1987 07:41:01.59\u0005\u0005\u0005A</td>\n",
       "      <td>[money-fx, dlr, yen]</td>\n",
       "      <td>[japan]</td>\n",
       "      <td>10364</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "13457         SOVIET GRAIN PRODUCTS MINISTRY CRITICISED   \n",
       "3318     CHRYSLER <C> TO CLOSE INDIANA ELECTRICAL PLANT   \n",
       "17501  SPECTRA-PHYSICS <SPY> BOARD REJECTS TENDER OFFER   \n",
       "10213   CANAMAX, PACIFIC TRANS-OCEAN APPROVE PRODUCTION   \n",
       "10363    JAPAN SETS ASIDE YEN FUNDS TO PREVENT DLR FALL   \n",
       "\n",
       "                                                    body  \\\n",
       "13457  The Soviet Communist Party has criticised\\nthe...   \n",
       "3318   Chrysler Corp said over the next two\\nyears it...   \n",
       "17501  Spectra-Physics Inc said its\\nboard rejected a...   \n",
       "10213  <Canamax Resources Inc> and <Pacific\\nTrans-Oc...   \n",
       "10363  The 50-day provisional 1987/88 budget,\\nadopte...   \n",
       "\n",
       "                              date                topics    places     id  \\\n",
       "13457   1987-04-07 06:13:53.760000               [grain]    [ussr]  13458   \n",
       "3318    1987-03-09 15:14:31.080000               unknown     [usa]   3319   \n",
       "17501       1-JUN-1987 09:09:43.36                 [acq]     [usa]  17502   \n",
       "10213      26-MAR-1987 17:26:07.23                [gold]  [canada]  10214   \n",
       "10363  27-MAR-1987 07:41:01.59\u0005\u0005\u0005A  [money-fx, dlr, yen]   [japan]  10364   \n",
       "\n",
       "      organisations  \n",
       "13457       unknown  \n",
       "3318        unknown  \n",
       "17501       unknown  \n",
       "10213       unknown  \n",
       "10363       unknown  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           [cocoa]\n",
       "1                                           unknown\n",
       "2                                           unknown\n",
       "3                                           unknown\n",
       "4        [grain, wheat, corn, barley, oat, sorghum]\n",
       "                            ...                    \n",
       "21573                                        [ship]\n",
       "21574                                         [ipi]\n",
       "21575                                        [gold]\n",
       "21576                                       unknown\n",
       "21577                                       unknown\n",
       "Name: topics, Length: 19043, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            [el-salvador, usa, uruguay]\n",
       "1                                                  [usa]\n",
       "2                                                  [usa]\n",
       "3                                          [usa, brazil]\n",
       "4                                                  [usa]\n",
       "                              ...                       \n",
       "21573    [hong-kong, japan, india, pakistan, iran, iraq]\n",
       "21574                                             [ussr]\n",
       "21575                                     [south-africa]\n",
       "21576                                      [switzerland]\n",
       "21577                                              [usa]\n",
       "Name: places, Length: 19043, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class cleansing:\\n    \\n    def __init__(self, punt):\\n        self.punt = punt\\n    \\n    def removenoise(self, string):\\n        string = string.lower()\\n        for i in string:\\n            string = string.replace(\\'\\n\\',\\'\\')\\n            string = re.sub(\"\\\\d+\", \" \", string)\\n            string = re.sub(r\\'\\\\W\\',\\' \\', string)\\n            string = re.sub(r\\'\\\\s+\\',\\' \\',string)\\n        string  = \"\".join([i for i in string if i not in self.punt])\\n        return string\\n    \\n    def removestopwords(self, string):\\n        text_tokens = word_tokenize(string)\\n        stop_words = stopwords.words(\\'english\\')\\n        cleaned_words = [w for w in text_tokens if w not in stop_words]\\n        cleaned_stopwords = \" \".join(cleaned_words)\\n        return cleaned_stopwords\\n\\n    \\n    def stemwords(self, string):\\n        split_words = []\\n        for i in string.split(\" \"):\\n            split_words.append(i)\\n        stem_words = []\\n        stemmer = PorterStemmer()\\n        stemmed_words = [stemmer.stem(w) for w in split_words]\\n        for i in stemmed_words:\\n            check_spell = TextBlob(i)\\n            stem_words.append(str(check_spell.correct()))\\n        stem_words = \" \".join(stem_words)\\n        return stemmed\\n                              \\n    def word_tokenizer(self, string):\\n        text_tokens = word_tokenize(string)\\n        return text_tokens\\n        \\n    def allinone(self,string):\\n        noised = self.removenoise(string)\\n        cleaned = self.removestopwords(noised)\\n        stemmed = self.stemwords(cleaned)\\n        tokens = self.word_tokenizer(stemmed)\\n        return tokens'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class cleansing:\n",
    "    \n",
    "    def __init__(self, punt):\n",
    "        self.punt = punt\n",
    "    \n",
    "    def removenoise(self, string):\n",
    "        string = string.lower()\n",
    "        for i in string:\n",
    "            string = string.replace('\\n','')\n",
    "            string = re.sub(\"\\d+\", \" \", string)\n",
    "            string = re.sub(r'\\W',' ', string)\n",
    "            string = re.sub(r'\\s+',' ',string)\n",
    "        string  = \"\".join([i for i in string if i not in self.punt])\n",
    "        return string\n",
    "    \n",
    "    def removestopwords(self, string):\n",
    "        text_tokens = word_tokenize(string)\n",
    "        stop_words = stopwords.words('english')\n",
    "        cleaned_words = [w for w in text_tokens if w not in stop_words]\n",
    "        cleaned_stopwords = \" \".join(cleaned_words)\n",
    "        return cleaned_stopwords\n",
    "\n",
    "    \n",
    "    def stemwords(self, string):\n",
    "        split_words = []\n",
    "        for i in string.split(\" \"):\n",
    "            split_words.append(i)\n",
    "        stem_words = []\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_words = [stemmer.stem(w) for w in split_words]\n",
    "        for i in stemmed_words:\n",
    "            check_spell = TextBlob(i)\n",
    "            stem_words.append(str(check_spell.correct()))\n",
    "        stem_words = \" \".join(stem_words)\n",
    "        return stemmed\n",
    "                              \n",
    "    def word_tokenizer(self, string):\n",
    "        text_tokens = word_tokenize(string)\n",
    "        return text_tokens\n",
    "        \n",
    "    def allinone(self,string):\n",
    "        noised = self.removenoise(string)\n",
    "        cleaned = self.removestopwords(noised)\n",
    "        stemmed = self.stemwords(cleaned)\n",
    "        tokens = self.word_tokenizer(stemmed)\n",
    "        return tokens\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = df['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = cleansing('\\â€œ:â€&;?!\"#$%&\\'()*+/,.:;<=>?[\\\\]^_`{|}~¡¬´')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body_cleaned = []\\nfor i in body:\\n    body_cleaned.append(model.removenoise(i))'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"body_cleaned = []\n",
    "for i in body:\n",
    "    body_cleaned.append(model.removenoise(i))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body_cleaned'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"body_cleaned\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tweets_cleaned = []\\nfor tweet in df.body:\\n    tweets_cleaned.append(model.allinone(tweet))'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tweets_cleaned = []\n",
    "for tweet in df.body:\n",
    "    tweets_cleaned.append(model.allinone(tweet))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def removestopwords(self, string):\\n        stem_words = []\\n        text_tokens = word_tokenize(string)\\n        stemmer = PorterStemmer()\\n        stemmed_words = [stemmer.stem(w) for w in text_tokens]\\n        for i in stemmed_words:\\n            check_spell = TextBlob(word) \\n            stem_words.append(str(check_spell.correct())\\n        stemmed = \" \".join(stem_words)\\n        return stemmed'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def removestopwords(self, string):\n",
    "        stem_words = []\n",
    "        text_tokens = word_tokenize(string)\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_words = [stemmer.stem(w) for w in text_tokens]\n",
    "        for i in stemmed_words:\n",
    "            check_spell = TextBlob(word) \n",
    "            stem_words.append(str(check_spell.correct())\n",
    "        stemmed = \" \".join(stem_words)\n",
    "        return stemmed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def stemWords(self, string):\\n       \\n        This function performs stemming of words by chopping off inlfections of words using Port Stemmer algorithm.\\n        Also it corrects mispelling of words.\\n       \\n        words = []\\n        stemmed = []\\n        for i in string.split(\" \"):\\n            words.append(i)\\n        stemmer = PorterStemmer() #it is used PorterStemmer to reducing inflection of words to their original word form\\n        stemmed_words = [stemmer.stem(w) for w in words] #it is applied to each word\\n        for word in stemmed_words:\\n            check_spell = TextBlob(word) #again, we use spelling checking as some words might result mispelled or not complete\\n            stemmed.append(str(check_spell.correct()))\\n        stemmed = \" \".join(stemmed)\\n        return stemmed'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def stemWords(self, string):\n",
    "       \n",
    "        This function performs stemming of words by chopping off inlfections of words using Port Stemmer algorithm.\n",
    "        Also it corrects mispelling of words.\n",
    "       \n",
    "        words = []\n",
    "        stemmed = []\n",
    "        for i in string.split(\" \"):\n",
    "            words.append(i)\n",
    "        stemmer = PorterStemmer() #it is used PorterStemmer to reducing inflection of words to their original word form\n",
    "        stemmed_words = [stemmer.stem(w) for w in words] #it is applied to each word\n",
    "        for word in stemmed_words:\n",
    "            check_spell = TextBlob(word) #again, we use spelling checking as some words might result mispelled or not complete\n",
    "            stemmed.append(str(check_spell.correct()))\n",
    "        stemmed = \" \".join(stemmed)\n",
    "        return stemmed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing(object):\n",
    "    \n",
    "    def __init__(self, punt):\n",
    "        self.punt = punt \n",
    "    \n",
    "    def removenoise(self, string):\n",
    "        #removing punctuation signs\n",
    "        #string = string.lower()\n",
    "        for i in self.punt:\n",
    "            string = string.replace(i, '')\n",
    "        for i in string:\n",
    "            string = string.replace('\\n','')\n",
    "            string = re.sub(\"\\d+\", \" \", string)\n",
    "            string = re.sub(r'\\W',' ', string)\n",
    "            string = re.sub(r'\\s+',' ', string)\n",
    "        #removing stopwords\n",
    "        text_tokens = word_tokenize(string)\n",
    "        stop_words = stopwords.words('english')\n",
    "        cleaned_words = [w for w in text_tokens if w not in stop_words]\n",
    "        cleaned_stopwords = \" \".join(cleaned_words)\n",
    "        return cleaned_stopwords\n",
    "    \n",
    "    def stemwords(self, string):\n",
    "        split_words = []\n",
    "        for i in string.split(\" \"):\n",
    "            split_words.append(i)\n",
    "        stem_words = []\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_words = [stemmer.stem(w) for w in split_words]\n",
    "        stem_words = \" \".join(stem_words)\n",
    "        return stem_words\n",
    "                              \n",
    "    def word_tokenizer(self, string):\n",
    "        text_tokens = word_tokenize(string)\n",
    "        return text_tokens\n",
    "        \n",
    "    def allinone(self,string):\n",
    "        noised = self.removenoise(string)\n",
    "        stemmed = self.stemwords(noised)\n",
    "        tokens = self.word_tokenizer(stemmed)\n",
    "        return tokens\n",
    "    \n",
    "    def dataframeclean(selfdev, dataframe):\n",
    "        dataframe['clean_comment'] = dataframe.body.apply(selfdev.allinone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing=preprocessing('\\â€œ:â€&;?!\"#$%&\\'()*+/,.:;<=>?[\\\\]^_`{|}~¡¬´')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = df['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b6c42fb64ea8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremovenoise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-0b6282c8acb6>\u001b[0m in \u001b[0;36mremovenoise\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\d+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\W'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\s+'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "Preprocessing.removenoise(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing.dataframeclean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
